import os
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from scipy.io.wavfile import write as write_wav
import wx
import wx.media
import matplotlib.pyplot as plt
from matplotlib.backends.backend_wxagg import FigureCanvasWxAgg as FigureCanvas
from matplotlib.figure import Figure

# Set random seed for reproducibility
torch.manual_seed(42)
np.random.seed(42)

# Hyperparameters
latent_dim = 10
signal_length = 44100
batch_size = 64
epochs = 50000
sample_interval = 1000
num_samples = 1000

# Generate real data (tones)
def generate_real_tones(n_samples):
    X = np.zeros((n_samples, signal_length))
    for i in range(n_samples):
        frequency = np.random.uniform(100, 2000)  # Wider frequency range
        amplitude = np.random.uniform(0.5, 1.0)   # Random amplitude
        phase = np.random.uniform(0, 2 * np.pi)   # Random phase
        t = np.linspace(0, 1, signal_length, endpoint=False)
        X[i] = amplitude * np.sin(2 * np.pi * frequency * t + phase)
    X = X.astype(np.float32)
    y = torch.ones((n_samples, 1), dtype=torch.float32)
    return torch.tensor(X), y

# Compute gradient penalty for WGAN-GP
def compute_gradient_penalty(discriminator, real_samples, fake_samples, device):
    alpha = torch.rand(real_samples.size(0), 1).to(device)
    interpolates = (alpha * real_samples + ((1 - alpha) * fake_samples)).requires_grad_(True)
    d_interpolates = discriminator(interpolates)
    gradients = torch.autograd.grad(
        outputs=d_interpolates,
        inputs=interpolates,
        grad_outputs=torch.ones(d_interpolates.size()).to(device),
        create_graph=True,
        retain_graph=True,
        only_inputs=True
    )[0]
    gradients = gradients.view(gradients.size(0), -1)
    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()
    return gradient_penalty

# Build the Generator
generator = nn.Sequential(
    nn.Linear(latent_dim, 256),
    nn.LeakyReLU(0.2),
    nn.Linear(256, 512),
    nn.LeakyReLU(0.2),
    nn.Linear(512, signal_length),
    nn.Tanh()
)

# Build the Discriminator
discriminator = nn.Sequential(
    nn.Linear(signal_length, 512),
    nn.LeakyReLU(0.2),
    nn.Linear(512, 256),
    nn.LeakyReLU(0.2),
    nn.Linear(256, 1)
)

# Optimizers
optimizer_G = optim.Adam(generator.parameters(), lr=0.00005, betas=(0.5, 0.999))
optimizer_D = optim.Adam(discriminator.parameters(), lr=0.00005, betas=(0.5, 0.999))

# Loss function (MSE for smoother convergence)
criterion = nn.MSELoss()

# Precompute a dataset of real tones
real_dataset = []
for _ in range(num_samples // batch_size):
    X_real, _ = generate_real_tones(batch_size)
    real_dataset.append(X_real)

# Training loop
def train_gan(generator, discriminator, optimizer_G, optimizer_D, latent_dim, epochs, batch_size, sample_interval):
    device = torch.device("cpu")
    generator.to(device)
    discriminator.to(device)

    for epoch in range(epochs):
        # Train Discriminator
        optimizer_D.zero_grad()

        # Real data
        X_real = real_dataset[epoch % len(real_dataset)].to(device)
        y_real = torch.full((batch_size, 1), 0.9, dtype=torch.float32).to(device)  # Smoothed real labels
        real_output = discriminator(X_real)
        d_loss_real = criterion(real_output, y_real)

        # Fake data
        noise = torch.randn(batch_size, latent_dim, dtype=torch.float32).to(device)
        X_fake = generator(noise).detach()
        y_fake = torch.full((batch_size, 1), 0.1, dtype=torch.float32).to(device)  # Smoothed fake labels
        fake_output = discriminator(X_fake)
        d_loss_fake = criterion(fake_output, y_fake)

        # Gradient penalty
        gradient_penalty = compute_gradient_penalty(discriminator, X_real, X_fake, device)

        # Total discriminator loss
        d_loss = d_loss_real + d_loss_fake + 10 * gradient_penalty
        d_loss.backward()
        optimizer_D.step()

        # Train Generator
        optimizer_G.zero_grad()
        noise = torch.randn(batch_size, latent_dim, dtype=torch.float32).to(device)
        X_fake = generator(noise)
        fake_output = discriminator(X_fake)
        g_loss = criterion(fake_output, torch.full((batch_size, 1), 0.9, dtype=torch.float32).to(device))  # Smoothed target
        g_loss.backward()
        optimizer_G.step()

        # Print progress
        if epoch % sample_interval == 0:
            print(f"Epoch {epoch}, D Loss: {d_loss.item():.4f}, G Loss: {g_loss.item():.4f}")

    # Save models
    torch.save(generator.state_dict(), 'models/generator_final.pth')
    torch.save(discriminator.state_dict(), 'models/discriminator_final.pth')

# Load the pre-trained generator model
class AudioGANApp(wx.App):
    def __init__(self, generator_path, output_dir="output"):
        self.generator_path = generator_path
        self.output_dir = output_dir
        os.makedirs(self.output_dir, exist_ok=True)
        super().__init__()

    def OnInit(self):
        # Initialize the main frame
        frame = wx.Frame(None, title="Audio GAN App", size=(800, 600))
        panel = wx.Panel(frame)

        # Create a vertical sizer for layout
        main_sizer = wx.BoxSizer(wx.VERTICAL)

        # Add buttons
        button_sizer = wx.BoxSizer(wx.HORIZONTAL)
        generate_button = wx.Button(panel, label="Generate Tone")
        save_button = wx.Button(panel, label="Save Tone")
        play_button = wx.Button(panel, label="Play Tone")
        plot_button = wx.Button(panel, label="Plot Tone")
        fft_button = wx.Button(panel, label="Plot FFT")

        # Bind events
        generate_button.Bind(wx.EVT_BUTTON, self.on_generate_tone)
        save_button.Bind(wx.EVT_BUTTON, self.on_save_tone)
        play_button.Bind(wx.EVT_BUTTON, self.on_play_tone)
        plot_button.Bind(wx.EVT_BUTTON, self.on_plot_tone)
        fft_button.Bind(wx.EVT_BUTTON, self.on_plot_fft)

        # Add buttons to the button sizer
        button_sizer.Add(generate_button, 0, wx.ALL | wx.EXPAND, 5)
        button_sizer.Add(save_button, 0, wx.ALL | wx.EXPAND, 5)
        button_sizer.Add(play_button, 0, wx.ALL | wx.EXPAND, 5)
        button_sizer.Add(plot_button, 0, wx.ALL | wx.EXPAND, 5)
        button_sizer.Add(fft_button, 0, wx.ALL | wx.EXPAND, 5)

        # Add the button sizer to the main sizer
        main_sizer.Add(button_sizer, 0, wx.ALL | wx.EXPAND, 5)

        # Create a Matplotlib figure and canvas
        self.figure = Figure(figsize=(7, 4), dpi=100)
        self.canvas = FigureCanvas(panel, -1, self.figure)
        self.axes = self.figure.add_subplot(111)
        self.axes.set_title("Generated Tone Waveform")
        self.axes.set_xlabel("Sample Index")
        self.axes.set_ylabel("Amplitude")
        self.axes.grid(True)

        # Add the canvas to the main sizer
        main_sizer.Add(self.canvas, 1, wx.ALL | wx.EXPAND, 5)

        # Set the main sizer for the panel
        panel.SetSizer(main_sizer)
        frame.Show()

        # Load the generator model
        try:
            self.device = torch.device("cpu")
            self.latent_dim = latent_dim
            self.signal_length = signal_length
            self.generator = self.load_generator()
        except Exception as e:
            wx.MessageBox(f"Failed to load the generator: {e}", "Error", wx.OK | wx.ICON_ERROR)
            return False

        return True

    def load_generator(self):
        """Load the pre-trained generator model."""
        generator = nn.Sequential(
            nn.Linear(self.latent_dim, 256),
            nn.LeakyReLU(0.2),
            nn.Linear(256, 512),
            nn.LeakyReLU(0.2),
            nn.Linear(512, self.signal_length),
            nn.Tanh()
        ).to(self.device)

        try:
            generator.load_state_dict(torch.load(self.generator_path, map_location=self.device))
            generator.eval()
            print("Generator loaded successfully.")
        except Exception as e:
            raise RuntimeError(f"Failed to load generator state dict: {e}")

        return generator

    def generate_tone(self):
        """Generate a tone using the generator."""
        noise = torch.randn(1, self.latent_dim, dtype=torch.float32).to(self.device)
        with torch.no_grad():
            generated_signal = self.generator(noise).cpu().numpy().flatten()

        normalized_signal = (generated_signal / np.max(np.abs(generated_signal))) * 32767
        normalized_signal = np.clip(normalized_signal, -32767, 32767).astype(np.int16)
        self.generated_signal = normalized_signal
        print("Tone generated successfully.")

        # Update the plot
        self.update_plot()

    def save_tone(self):
        """Save the generated tone as an audio file."""
        if not hasattr(self, "generated_signal"):
            wx.MessageBox("Please generate a tone first.", "Error", wx.OK | wx.ICON_ERROR)
            return

        output_path = os.path.join(self.output_dir, "generated_tone.wav")
        try:
            write_wav(output_path, 44100, self.generated_signal)
            print(f"Tone saved to {output_path}.")
            wx.MessageBox(f"Tone saved to {output_path}.", "Success", wx.OK | wx.ICON_INFORMATION)
        except Exception as e:
            wx.MessageBox(f"Failed to save tone: {e}", "Error", wx.OK | wx.ICON_ERROR)

    def play_tone(self):
        """Play the generated tone."""
        if not hasattr(self, "generated_signal"):
            wx.MessageBox("Please generate a tone first.", "Error", wx.OK | wx.ICON_ERROR)
            return

        output_path = os.path.join(self.output_dir, "temp_tone.wav")
        try:
            write_wav(output_path, 44100, self.generated_signal)
        except Exception as e:
            wx.MessageBox(f"Failed to write temporary tone file: {e}", "Error", wx.OK | wx.ICON_ERROR)
            return

        # Play the audio file
        if hasattr(self, "player") and self.player.IsPlaying():
            self.player.Stop()

        self.player = wx.media.MediaCtrl(self.TopWindow)
        if self.player.Load(output_path):
            self.player.Play()
        else:
            wx.MessageBox("Failed to load the audio file.", "Error", wx.OK | wx.ICON_ERROR)

    def update_plot(self):
        """Update the embedded plot with the generated tone."""
        if not hasattr(self, "generated_signal"):
            wx.MessageBox("Please generate a tone first.", "Error", wx.OK | wx.ICON_ERROR)
            return

        # Normalize the signal for plotting
        normalized_signal = self.generated_signal / 32767.0

        # Clear the previous plot
        self.axes.clear()

        # Plot the new waveform
        self.axes.plot(normalized_signal, color='blue', linewidth=0.5)
        self.axes.set_title("Generated Tone Waveform")
        self.axes.set_xlabel("Sample Index")
        self.axes.set_ylabel("Amplitude")
        self.axes.grid(True)

        # Redraw the canvas
        self.canvas.draw()

    def plot_fft(self):
        """Plot the frequency spectrum of the generated tone."""
        if not hasattr(self, "generated_signal"):
            wx.MessageBox("Please generate a tone first.", "Error", wx.OK | wx.ICON_ERROR)
            return

        fft_signal = np.fft.fft(self.generated_signal)
        frequencies = np.fft.fftfreq(len(fft_signal), 1 / 44100)

        plt.figure(figsize=(8, 4))
        plt.plot(frequencies[:len(frequencies) // 2], np.abs(fft_signal)[:len(fft_signal) // 2], color='blue')
        plt.title("Frequency Spectrum of Generated Tone")
        plt.xlabel("Frequency (Hz)")
        plt.ylabel("Amplitude")
        plt.grid(True)
        plt.tight_layout()
        plt.show()

    def on_generate_tone(self, event):
        """Event handler for generating a tone."""
        self.generate_tone()

    def on_save_tone(self, event):
        """Event handler for saving the tone."""
        self.save_tone()

    def on_play_tone(self, event):
        """Event handler for playing the tone."""
        self.play_tone()

    def on_plot_tone(self, event):
        """Event handler for plotting the tone."""
        self.update_plot()

    def on_plot_fft(self, event):
        """Event handler for plotting the FFT."""
        self.plot_fft()


if __name__ == "__main__":
    # Path to the pre-trained generator model
    generator_path = "models/generator_final.pth"

    # Check if the generator file exists
    if not os.path.exists(generator_path):
        print(f"Error: Generator file not found at {generator_path}.")
    else:
        # Start the app
        app = AudioGANApp(generator_path)
        app.MainLoop()